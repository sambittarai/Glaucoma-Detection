{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"mount_file_id":"1oXW3a6GNMHNMe6W9QSe5GWj5ntfmapVW","authorship_tag":"ABX9TyPwQksdh1VRvu47GXD2DDCr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"d_0_Jbu9ILyc","executionInfo":{"status":"ok","timestamp":1622785363708,"user_tz":-330,"elapsed":429,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}}},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Glaucoma_Detection')\n","sys.path.append('/content/drive/MyDrive/Glaucoma_Detection/utils')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2k2R-u8qYlWq","executionInfo":{"status":"ok","timestamp":1622785368579,"user_tz":-330,"elapsed":3560,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"8d063105-ed35-4dc9-9717-e769426495b7"},"source":["pip install tensorboardx"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorboardx\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n","\r\u001b[K     |██▊                             | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (57.0.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (1.15.0)\n","Installing collected packages: tensorboardx\n","Successfully installed tensorboardx-2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c7Ql9oqBYmN6","executionInfo":{"status":"ok","timestamp":1622785379577,"user_tz":-330,"elapsed":9691,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}}},"source":["import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","from tqdm import tqdm\n","import random,sys,time\n","import os\n","import torch\n","from utils.extract_patches import get_data_train\n","from utils.losses.loss import *\n","from utils.visualize import group_images, save_img\n","from utils.common import *\n","from utils.dataset import TrainDataset,TestDataset\n","from torch.utils.data import DataLoader\n","# from config import parse_args\n","from utils.logger import Logger, Print_Logger\n","from collections import OrderedDict\n","from utils.metrics import Evaluate\n","from Model_Architecture import UNetFamily"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8td6VNNKZJTI","executionInfo":{"status":"ok","timestamp":1622785382623,"user_tz":-330,"elapsed":406,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}}},"source":["#  Load the data and extract patches\n","def get_dataloader(train_data_path_list, train_patch_height, train_patch_width, stride_height, stride_width, val_ratio, batch_size, outf, save):\n","    patches_imgs_train, patches_masks_train = get_data_train(\n","        data_path_list = train_data_path_list,\n","        patch_height = train_patch_height,\n","        patch_width = train_patch_width,\n","        stride_height = stride_height,\n","        stride_width = stride_width\n","    )\n","\n","    print(patches_imgs_train.shape, patches_masks_train.shape)\n","\n","    val_ind = random.sample(range(patches_masks_train.shape[0]),int(np.floor(val_ratio*patches_masks_train.shape[0])))\n","    train_ind =  set(range(patches_masks_train.shape[0])) - set(val_ind)\n","    train_ind = list(train_ind)\n","\n","    train_set = TrainDataset(patches_imgs_train[train_ind,...],patches_masks_train[train_ind,...],mode=\"train\")\n","    train_loader = DataLoader(train_set, batch_size=batch_size,\n","                              shuffle=True, num_workers=4)\n","\n","    val_set = TrainDataset(patches_imgs_train[val_ind,...],patches_masks_train[val_ind,...],mode=\"val\")\n","    val_loader = DataLoader(val_set, batch_size=batch_size,\n","                            shuffle=False, num_workers=4)\n","    \n","    #Save some samples of feeding to the neural network\n","    # N_sample = min(patches_imgs_train.shape[0], 50)\n","    # save_img(group_images((patches_imgs_train[0:N_sample, :, :, :]*255).astype(np.uint8), 10),\n","    #           os.path.join(outf, save, \"sample_input_imgs.png\"))\n","    # save_img(group_images((patches_masks_train[0:N_sample, :, :, :]*255).astype(np.uint8), 10),\n","    #           os.path.join(outf, save,\"sample_input_masks.png\"))\n","\n","    return train_loader,val_loader\n","\n","# train \n","def train(train_loader,net,criterion,optimizer,device):\n","    net.train()\n","    train_loss = AverageMeter()\n","\n","    for batch_idx, (inputs, targets) in tqdm(enumerate(train_loader), total=len(train_loader)):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss.update(loss.item(), inputs.size(0))\n","    log = OrderedDict([('train_loss',train_loss.avg)])\n","    return log\n","\n","# val \n","def val(val_loader,net,criterion,device):\n","    net.eval()\n","    val_loss = AverageMeter()\n","    evaluater = Evaluate()\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in tqdm(enumerate(val_loader), total=len(val_loader)):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","            val_loss.update(loss.item(), inputs.size(0))\n","\n","            outputs = outputs.data.cpu().numpy()\n","            targets = targets.data.cpu().numpy()\n","            evaluater.add_batch(targets,outputs[:,1])\n","    log = OrderedDict([('val_loss', val_loss.avg), \n","                       ('val_acc', evaluater.confusion_matrix()[1]), \n","                       ('val_f1', evaluater.f1_score()),\n","                       ('val_auc_roc', evaluater.auc_roc())])\n","    return log"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIx9VLGqbxcQ","executionInfo":{"status":"ok","timestamp":1622785447415,"user_tz":-330,"elapsed":60230,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"ccee0e56-92ab-4c63-f6aa-5b3f9495dff9"},"source":["setpu_seed(2021)\n","\n","outf = \"/content/drive/MyDrive/Glaucoma_Detection/Experiments\"\n","save = \"Optic_Disc_Seg\"\n","save_path = os.path.join(outf, save)\n","\n","if not os.path.exists(save_path):\n","  os.mkdir(save_path)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() and True else \"cpu\")\n","cudnn.benchmark = True\n","log = Logger(save_path)\n","sys.stdout = Print_Logger(os.path.join(save_path,'train_log.txt'))\n","print('The computing device used is: ','GPU' if device.type=='cuda' else 'CPU')\n","\n","net = UNetFamily.U_Net(1,2).to(device)\n","print(\"Total number of parameters: \" + str(count_parameters(net)))\n","log.save_graph(net,torch.randn((1,1,128,128)).to(device).to(device=device))\n","\n","N_epochs = 20\n","start_epoch = 1\n","criterion = CrossEntropyLoss2d() # Initialize loss function\n","optimizer = optim.Adam(net.parameters(), lr=0.0005)\n","lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_epochs, eta_min=0)\n","train_data_path_list = \"/content/drive/MyDrive/Glaucoma_Detection/Dataset_Preparation/data_path_list/IDRiD/train.txt\"\n","train_patch_height, train_patch_width = 128, 128\n","stride_height, stride_width = 64, 64\n","val_ratio = 0.05\n","batch_size = 48\n","\n","train_loader, val_loader = get_dataloader(train_data_path_list, train_patch_height, train_patch_width,\n","                                          stride_height, stride_width, val_ratio, batch_size, outf, save) # create dataloader"],"execution_count":5,"outputs":[{"output_type":"stream","text":["The computing device used is:  GPU\n","Total number of parameters: 34525954\n","Architecture of Model have saved in Tensorboard!\n","\u001b[0;33mload data from /content/drive/MyDrive/Glaucoma_Detection/Dataset_Preparation/data_path_list/IDRiD/train.txt \u001b[0m\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["ori data shape < ori_imgs:(54, 3, 1112, 1012) GTs:(54, 1, 1112, 1012)\n","imgs pixel range 0-255: \n","GTs pixel range 0-255: \n","==================data have loaded======================\n","\n","the side H is not compatible with the selected stride of 64\n","(img_h - patch_h) MOD stride_h: 24\n","So the H dim will be padded with additional 40 pixels\n","the side W is not compatible with the selected stride of 64\n","(img_w - patch_w) MOD stride_w: 52\n","So the W dim will be padded with additional 12 pixels\n","new padded images shape: (54, 1, 1152, 1024)\n","\n","the side H is not compatible with the selected stride of 64\n","(img_h - patch_h) MOD stride_h: 24\n","So the H dim will be padded with additional 40 pixels\n","the side W is not compatible with the selected stride of 64\n","(img_w - patch_w) MOD stride_w: 52\n","So the W dim will be padded with additional 12 pixels\n","new padded images shape: (54, 1, 1152, 1024)\n","\n","Train images shape: (54, 1, 1152, 1024), value range (0.0 - 1.0):\n","\n","Traint masks shape: (54, 1, 1152, 1024), value range (0.0 - 1.0):\n","Number of patches on h : 17\n","Number of patches on w : 15\n","number of patches per image: 255, totally for testset: 13770\n","Number of patches on h : 17\n","Number of patches on w : 15\n","number of patches per image: 255, totally for testset: 13770\n","train patches shape: (13770, 1, 128, 128), value range (0.0 - 1.0)\n","train patches shape: (13770, 1, 128, 128), value range (0.0 - 1.0)\n","(13770, 1, 128, 128) (13770, 1, 128, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJoGx5Nvdk4S","executionInfo":{"status":"ok","timestamp":1622785455405,"user_tz":-330,"elapsed":437,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"031357a2-b10e-4aa9-8643-ecfc97ca2662"},"source":["len(train_loader), len(val_loader)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(273, 15)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"-jYtWtbmiOQc"},"source":["# Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mN8N4vsiP2P","executionInfo":{"status":"ok","timestamp":1622790284963,"user_tz":-330,"elapsed":4825895,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"169571d3-1f50-47fb-c6cc-b407d81b9caf"},"source":["best = {'epoch':0,'AUC_roc':0.5} # Initialize the best epoch and performance(AUC of ROC)\n","trigger = 0  # Early stop Counter\n","\n","for epoch in range(start_epoch,N_epochs+1):\n","  print('\\nEPOCH: %d/%d --(learn_rate:%.6f) | Time: %s' % \\\n","            (epoch, N_epochs,optimizer.state_dict()['param_groups'][0]['lr'], time.asctime()))\n","  \n","  # train stage\n","  train_log = train(train_loader,net,criterion, optimizer,device)\n","  # val stage\n","  val_log = val(val_loader,net,criterion,device)\n","\n","  log.update(epoch,train_log,val_log) # Add log information\n","  lr_scheduler.step()\n","\n","  # Save checkpoint of latest and best model\n","  state = {'net': net.state_dict(),'optimizer':optimizer.state_dict(),'epoch': epoch}\n","  # torch.save(state, os.path.join(save_path, 'latest_model.pth'))\n","  trigger += 1\n","  if val_log['val_auc_roc'] > best['AUC_roc']:\n","    print('\\033[0;33mSaving best model!\\033[0m')\n","    torch.save(state, os.path.join(save_path, 'best_model.pth'))\n","    best['epoch'] = epoch\n","    best['AUC_roc'] = val_log['val_auc_roc']\n","    trigger = 0\n","\n","  print('Best performance at Epoch: {} | AUC_roc: {}'.format(best['epoch'],best['AUC_roc']))\n","\n","  # early stopping\n","  early_stop = 6\n","  if not early_stop is None:\n","    if trigger >= early_stop:\n","      print(\"=> early stopping\")\n","      break\n","\n","  torch.cuda.empty_cache()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:33<00:00,  1.28it/s]\n","100%|██████████| 15/15 [00:05<00:00,  2.76it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:23<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:23<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.52it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.52it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.46it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.46it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.33it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.43it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.45it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.33it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.45it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.33it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.34it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.43it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.33it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 273/273 [03:24<00:00,  1.33it/s]\n","100%|██████████| 15/15 [00:04<00:00,  3.46it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2wF8Gv7YiLqa"},"source":["# Visualization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPBKawiIgahP","executionInfo":{"status":"ok","timestamp":1622784794971,"user_tz":-330,"elapsed":4845,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"d4971e18-dd13-425b-82e2-ae35a50bb9ff"},"source":["net.train()\n","for batch_idx, (inputs, targets) in tqdm(enumerate(train_loader), total=len(train_loader)):\n","  inputs, targets = inputs.to(device), targets.to(device)\n","  optimizer.zero_grad()\n","  outputs = net(inputs)\n","  break"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","  0%|          | 0/205 [00:04<?, ?it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWV6VtCYghsn","executionInfo":{"status":"ok","timestamp":1622784827921,"user_tz":-330,"elapsed":490,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"5371f6ad-1cb0-43f6-bd97-b15681a80ddc"},"source":["type(inputs), type(outputs), type(targets)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Tensor, torch.Tensor, torch.Tensor)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VI-qtxNYg113","executionInfo":{"status":"ok","timestamp":1622784932710,"user_tz":-330,"elapsed":410,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"3d2ea3d2-ae69-482a-ae61-e47e89b050e9"},"source":["input = inputs.cpu().detach().numpy()\n","output = outputs.cpu().detach().numpy()\n","target = targets.cpu().detach().numpy()\n","\n","type(input), type(output), type(target)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(numpy.ndarray, numpy.ndarray, numpy.ndarray)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwXvbvMxhDB3","executionInfo":{"status":"ok","timestamp":1622784956155,"user_tz":-330,"elapsed":429,"user":{"displayName":"Sambit Tarai","photoUrl":"","userId":"16391838389452556892"}},"outputId":"e2ff56a9-10f0-4df4-9bad-643fe0ab4437"},"source":["input.shape, output.shape, target.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((64, 1, 128, 128), (64, 2, 128, 128), (64, 128, 128))"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"r19GRt__hVLm"},"source":["import matplotlib.pyplot as plt\n","\n","for i in range(64):\n","  plt.imshow(input[i,0,:,:], cmap=\"gray\")\n","  plt.show()\n","  plt.imshow(output[i,0,:,:], cmap=\"gray\")\n","  plt.show()\n","  plt.imshow(target[i,:,:], cmap=\"gray\")\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHRvfVLFhl5N"},"source":[""],"execution_count":null,"outputs":[]}]}